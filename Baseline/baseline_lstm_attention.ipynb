{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "baseline_lstm_attention.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhruvdcoder/HyperA/blob/master/Baseline/baseline_lstm_attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xu3H6evzrjai",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torchtext import data,datasets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbK3nwV3AYh1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGnoTyrBeizU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs = data.Field(tokenize='spacy')\n",
        "answers = data.Field(sequential=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWzaZm_GhNO4",
        "colab_type": "code",
        "outputId": "334bcbe1-4c8b-4f20-952e-33f6552fd9de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "train, dev, test = datasets.MultiNLI.splits(inputs, answers)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading multinli_1.0.zip\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "multinli_1.0.zip: 100%|██████████| 227M/227M [02:23<00:00, 1.58MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "extracting\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtA801Q2dxwz",
        "colab_type": "code",
        "outputId": "22f39e8f-955d-42aa-88ac-da6a576632d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "inputs.build_vocab(train, dev, test)\n",
        "inputs.vocab.load_vectors('glove.6B.100d')\n",
        "answers.build_vocab(train)\n",
        "\n",
        "train_iter, dev_iter, test_iter = data.BucketIterator.splits((train, dev, test), batch_size=128, device=device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [04:41, 3.06MB/s]                           \n",
            "100%|█████████▉| 398524/400000 [00:16<00:00, 24218.32it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmAHTXnUqGcP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import torch.optim as optim\n",
        "\n",
        "def train(model):\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = optim.Adam(model.parameters(), lr=0.001)#, weight_decay=1e-5)\n",
        "\n",
        "  iterations = 0\n",
        "  start = time.time()\n",
        "  best_dev_acc = -1\n",
        "  header = '  Time Epoch Iteration Progress    (%Epoch)   Loss   Dev/Loss     Accuracy  Dev/Accuracy'\n",
        "  dev_log_template = ' '.join('{:>6.0f},{:>5.0f},{:>9.0f},{:>5.0f}/{:<5.0f} {:>7.0f}%,{:>8.6f},{:8.6f},{:12.4f},{:12.4f}'.split(','))\n",
        "  log_template =     ' '.join('{:>6.0f},{:>5.0f},{:>9.0f},{:>5.0f}/{:<5.0f} {:>7.0f}%,{:>8.6f},{},{:12.4f},{}'.split(','))\n",
        "  print(header)\n",
        "\n",
        "  for epoch in range(5):\n",
        "    train_iter.init_epoch()\n",
        "    n_correct, n_total = 0, 0\n",
        "    for batch_idx, batch in enumerate(train_iter):\n",
        "\n",
        "        # switch model to training mode, clear gradient accumulators\n",
        "        model.train(); optimizer.zero_grad()\n",
        "\n",
        "        iterations += 1\n",
        "\n",
        "        # forward pass\n",
        "        answer,attentions = model(batch)\n",
        "\n",
        "        # calculate accuracy of predictions in the current batch\n",
        "        n_correct += (torch.max(answer, 1)[1].view(batch.label.size()) == batch.label).sum().item()\n",
        "        n_total += batch.batch_size\n",
        "        train_acc = 100. * n_correct/n_total\n",
        "\n",
        "        # calculate loss of the network output with respect to training labels\n",
        "        loss = criterion(answer, batch.label)\n",
        "\n",
        "        # backpropagate and update optimizer learning rate\n",
        "        loss.backward(); optimizer.step()\n",
        "\n",
        "        if iterations % 1000 == 0:\n",
        "\n",
        "          # print progress message\n",
        "          print(log_template.format(time.time()-start, epoch, iterations, 1+batch_idx, len(train_iter), \n",
        "                                    100. * (1+batch_idx) / len(train_iter), loss.item(), ' '*8, n_correct/n_total*100, ' '*12))\n",
        "\n",
        "    # switch model to evaluation mode\n",
        "    model.eval(); dev_iter.init_epoch()\n",
        "\n",
        "    # calculate accuracy on validation set\n",
        "    n_dev_correct, dev_loss = 0, 0\n",
        "    with torch.no_grad():\n",
        "      for dev_batch_idx, dev_batch in enumerate(dev_iter):\n",
        "        answer,attentions = model(dev_batch)\n",
        "        n_dev_correct += (torch.max(answer, 1)[1].view(dev_batch.label.size()) == dev_batch.label).sum().item()\n",
        "        dev_loss = criterion(answer, dev_batch.label)\n",
        "    dev_acc = 100. * n_dev_correct / len(dev)\n",
        "\n",
        "    print(dev_log_template.format(time.time()-start,\n",
        "        epoch, iterations, 1+batch_idx, len(train_iter),\n",
        "        100. * (1+batch_idx) / len(train_iter), loss.item(), dev_loss.item(), train_acc, dev_acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5-tAtQY1sLu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "  def __init__(self,config):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.config = config\n",
        "    #self.rnn = nn.RNN(input_size=config['d_embed'], hidden_size=config['d_hidden'],num_layers=config['n_layers'])\n",
        "    #self.rnn = nn.GRU(input_size=config['d_embed'], hidden_size=config['d_hidden'],num_layers=config['n_layers'])\n",
        "    self.rnn = nn.LSTM(input_size=config['d_embed'], hidden_size=config['d_hidden'],num_layers=config['n_layers'])\n",
        "  \n",
        "  def forward(self,inputs):\n",
        "    #bsz = inputs.size()[1]\n",
        "    #h0 = c0 = inputs.new_zeros(config['n_layers'], bsz, config['d_hidden'])\n",
        "    #outputs, hidden = self.rnn(inputs)\n",
        "    outputs, (hidden,cell) = self.rnn(inputs)\n",
        "    return outputs if config['attn'] else outputs[-1]\n",
        "  \n",
        "class MultiNLIClassifier(nn.Module):\n",
        "  def __init__(self,config):\n",
        "    super(MultiNLIClassifier, self).__init__()\n",
        "    self.config = config\n",
        "    self.embed = nn.Embedding(config['n_embed'], config['d_embed'])\n",
        "    self.encoder = Encoder(config)\n",
        "    self.encoder_p = Encoder(config)\n",
        "    self.encoder_h = Encoder(config)\n",
        "    \n",
        "#     self.relu = nn.ReLU()\n",
        "#     self.tanh = nn.Tanh()\n",
        "#     self.proj_p = nn.Linear(config['d_hidden'], config['d_hidden'])\n",
        "#     self.proj_h = nn.Linear(config['d_hidden'], config['d_hidden'])\n",
        "#     self.W = nn.Parameter(torch.randn(config['d_hidden'], 1))\n",
        "#     self.register_parameter('W', self.W)\n",
        "#     self.Wp = nn.Linear(config['d_hidden'], config['d_hidden'])\n",
        "#     self.Wh = nn.Linear(config['d_hidden'], config['d_hidden'])\n",
        "\n",
        "    self.out = nn.Linear(2*config['d_hidden'], config['d_out'])\n",
        "  \n",
        "  def forward(self,batch):\n",
        "#     print(batch.premise)\n",
        "    pre_emb = self.embed(batch.premise)\n",
        "    hyp_emb = self.embed(batch.hypothesis)\n",
        "    if self.config['freeze_emb']:\n",
        "      pre_emb =pre_emb.detach()\n",
        "      hyp_emb =hyp_emb.detach()\n",
        "    if self.config['attn']:\n",
        "      #Attention\n",
        "      prem = self.encoder_p(pre_emb).transpose(0,1)\n",
        "      hypo = self.encoder_h(hyp_emb)[-1].unsqueeze(2)\n",
        "#     M = self.tanh(self.proj_p(prem)+self.proj_h(hypo[None,:,:]))\n",
        "#     alpha = nn.functional.softmax(torch.bmm(M, self.W.unsqueeze(0).expand(prem.size(0), *self.W.size())).squeeze(-1))\n",
        "#     r = torch.bmm(prem.permute(1,2,0),alpha.transpose(0,1).unsqueeze(2)).squeeze(2)\n",
        "#     h = self.tanh(self.Wp(r)+self.Wh(hypo))\n",
        "#     logits = self.out(h)\n",
        "      M = torch.bmm(prem,hypo)\n",
        "      alpha = nn.functional.softmax(M,1)\n",
        "      r = torch.bmm(prem.transpose(1,2),alpha)\n",
        "      logits = self.out(torch.cat([r.squeeze(2),hypo.squeeze(2)],1))\n",
        "    else:\n",
        "      prem = self.encoder(pre_emb)\n",
        "      hypo = self.encoder(hyp_emb)\n",
        "      logits = self.out(torch.cat([prem,hypo],1))\n",
        "    \n",
        "    return logits,alpha"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuBSvbuugxBT",
        "colab_type": "code",
        "outputId": "eb8ce59c-f2ab-4981-d99f-e7b59abc9e3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        }
      },
      "source": [
        "config = {}\n",
        "config['n_embed'] = len(inputs.vocab)\n",
        "config['d_embed'] = 100\n",
        "config['d_hidden'] = 300\n",
        "config['d_out'] = len(answers.vocab)\n",
        "config['n_layers'] = 1\n",
        "config['freeze_emb'] = 0\n",
        "config['attn'] = 1\n",
        "\n",
        "model = MultiNLIClassifier(config)\n",
        "print(model)\n",
        "model.embed.weight.data.copy_(inputs.vocab.vectors)\n",
        "model.to(device)\n",
        "train(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MultiNLIClassifier(\n",
            "  (embed): Embedding(93537, 100)\n",
            "  (encoder): Encoder(\n",
            "    (rnn): LSTM(100, 300)\n",
            "  )\n",
            "  (encoder_p): Encoder(\n",
            "    (rnn): LSTM(100, 300)\n",
            "  )\n",
            "  (encoder_h): Encoder(\n",
            "    (rnn): LSTM(100, 300)\n",
            "  )\n",
            "  (out): Linear(in_features=600, out_features=4, bias=True)\n",
            ")\n",
            "  Time Epoch Iteration Progress    (%Epoch)   Loss   Dev/Loss     Accuracy  Dev/Accuracy\n",
            "    35     0      1000  1000/3068       33% 0.933172               43.8156             \n",
            "    69     0      2000  2000/3068       65% 0.905636               49.1488             \n",
            "   103     0      3000  3000/3068       98% 0.823588               52.0299             \n",
            "   106     0      3068  3068/3068      100% 0.846418 0.912415      52.1670      58.8895\n",
            "   139     1      4000   932/3068       30% 0.865415               61.8227             \n",
            "   173     1      5000  1932/3068       63% 0.764624               62.0714             \n",
            "   207     1      6000  2932/3068       96% 0.796263               62.3828             \n",
            "   212     1      6136  3068/3068      100% 0.818024 0.882913      62.4084      60.7539\n",
            "   243     2      7000   864/3068       28% 0.599909               68.3268             \n",
            "   277     2      8000  1864/3068       61% 0.723363               68.1527             \n",
            "   311     2      9000  2864/3068       93% 0.607099               68.0511             \n",
            "   319     2      9204  3068/3068      100% 0.751440 0.853471      68.0274      61.2430\n",
            "   348     3     10000   796/3068       26% 0.588696               74.2904             \n",
            "   382     3     11000  1796/3068       59% 0.529190               73.6424             \n",
            "   417     3     12000  2796/3068       91% 0.640029               73.1950             \n",
            "   426     3     12272  3068/3068      100% 0.618740 0.861850      73.0989      60.1325\n",
            "   453     4     13000   728/3068       24% 0.595766               79.1960             \n",
            "   487     4     14000  1728/3068       56% 0.606345               78.5039             \n",
            "   521     4     15000  2728/3068       89% 0.514206               77.9288             \n",
            "   533     4     15340  3068/3068      100% 0.638665 0.759307      77.7366      60.3362\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwuPv2K2dTR4",
        "colab_type": "code",
        "outputId": "ee6a9b99-94a7-4345-cade-90447a3fb03a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([7, 128])\n",
            "torch.Size([7, 1])\n",
            "Our far distant neighbor . <pad> <pad>  torch.Size([7, 1])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJkAAAD8CAYAAABkZQZTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_NKX56CpnNO",
        "colab_type": "code",
        "outputId": "71c745f7-a17e-43e4-9bde-29e1ae97b7dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "class Batch:\n",
        "  def __init__(self,prem,hypo):\n",
        "    self.premise = prem\n",
        "    self.hypothesis = hypo\n",
        "\n",
        "def showAttention(input_sentence, attentions):\n",
        "    # Set up figure with colorbar\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(111)\n",
        "    cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
        "    fig.colorbar(cax)\n",
        "\n",
        "    # Set up axes\n",
        "#     ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
        "#                        ['<EOS>'], rotation=90)\n",
        "    ax.set_yticklabels([''] + input_sentence.split(' ') +\n",
        "                       ['<EOS>'])\n",
        "\n",
        "    # Show label at every tick\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()\n",
        "    \n",
        "    \n",
        "def evaluateAndShowAttention(premise,hypothesis):\n",
        "  prem = []\n",
        "  for word in premise.split(' '):\n",
        "    prem.append(inputs.vocab.stoi[word])\n",
        "  prem = torch.LongTensor(prem).unsqueeze(1)\n",
        "  \n",
        "  hypo = []\n",
        "  for word in hypothesis.split(' '):\n",
        "    hypo.append(inputs.vocab.stoi[word])\n",
        "  hypo = torch.LongTensor(hypo).unsqueeze(1)\n",
        "#   print(prem.shape,hypo.shape)\n",
        "  \n",
        "#   print(hypothesis)\n",
        "  batch = Batch(prem.cuda(),hypo.cuda())\n",
        "#   print(batch.hypothesis.shape)\n",
        "  \n",
        "  answer,attentions = model(batch)\n",
        "#   print(attentions.shape)\n",
        "#   print(premise,attentions[0].detach().cpu().shape)\n",
        "  print(hypothesis)\n",
        "  showAttention(premise, attentions[0].detach().cpu())\n",
        "\n",
        "# premise = 'Our close neighbour .'\n",
        "# hypothesis = 'Our far distant neighbor .'\n",
        "\n",
        "premise = 'A girl is wearing a blue jacket .'\n",
        "hypothesis = 'The jacket is blue .'\n",
        "\n",
        "model.eval()\n",
        "evaluateAndShowAttention(premise,hypothesis)\n",
        "\n",
        "# for test_batch_idx, test_batch in enumerate(test_iter):\n",
        "#   print(test_batch.premise.shape)\n",
        "#   answer,attentions = model(test_batch)\n",
        "#   print(attentions.shape)\n",
        "#   premise = ''\n",
        "#   hypothesis = ''\n",
        "#   for word_idx in test_batch.premise[:,1]:\n",
        "#     if (word_idx != 1):\n",
        "#       premise += inputs.vocab.itos[word_idx] + ' '\n",
        "\n",
        "#   for word_idx in test_batch.hypothesis[:,1]: \n",
        "# #     if (word_idx != 1):\n",
        "#       hypothesis += inputs.vocab.itos[word_idx] + ' '\n",
        "\n",
        "#   print(hypothesis,attentions[0].detach().cpu().shape)\n",
        "#   showAttention(hypothesis, attentions[0].detach().cpu())\n",
        "#   break"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-04bde96683d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0mhypothesis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'The jacket is blue .'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0mevaluateAndShowAttention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpremise\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhypothesis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vrbtt7vLBqj_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}