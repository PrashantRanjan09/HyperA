{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "baseline_lstm_attention.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhruvdcoder/HyperA/blob/master/Baseline/baseline_lstm_attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Xu3H6evzrjai",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchtext import data,datasets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hbK3nwV3AYh1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XGnoTyrBeizU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "inputs = data.Field(tokenize='spacy')\n",
        "answers = data.Field(sequential=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AWzaZm_GhNO4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "c8caaab5-6988-410d-9939-3d488d76b95a"
      },
      "cell_type": "code",
      "source": [
        "train, dev, test = datasets.MultiNLI.splits(inputs, answers)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading multinli_1.0.zip\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "multinli_1.0.zip: 100%|██████████| 227M/227M [05:21<00:00, 706kB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "extracting\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xtA801Q2dxwz",
        "colab_type": "code",
        "outputId": "18e4e4ae-461a-44d7-9a58-8ec194c77014",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "inputs.build_vocab(train, dev, test)\n",
        "inputs.vocab.load_vectors('glove.6B.100d')\n",
        "answers.build_vocab(train)\n",
        "\n",
        "train_iter, dev_iter, test_iter = data.BucketIterator.splits((train, dev, test), batch_size=128, device=device)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [01:17, 11.1MB/s]                           \n",
            " 99%|█████████▉| 397721/400000 [00:14<00:00, 26229.12it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "gmAHTXnUqGcP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "import torch.optim as optim\n",
        "\n",
        "def train(model):\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = optim.Adam(model.parameters(), lr=0.001)#, weight_decay=1e-5)\n",
        "\n",
        "  iterations = 0\n",
        "  start = time.time()\n",
        "  best_dev_acc = -1\n",
        "  header = '  Time Epoch Iteration Progress    (%Epoch)   Loss   Dev/Loss     Accuracy  Dev/Accuracy'\n",
        "  dev_log_template = ' '.join('{:>6.0f},{:>5.0f},{:>9.0f},{:>5.0f}/{:<5.0f} {:>7.0f}%,{:>8.6f},{:8.6f},{:12.4f},{:12.4f}'.split(','))\n",
        "  log_template =     ' '.join('{:>6.0f},{:>5.0f},{:>9.0f},{:>5.0f}/{:<5.0f} {:>7.0f}%,{:>8.6f},{},{:12.4f},{}'.split(','))\n",
        "  print(header)\n",
        "\n",
        "  for epoch in range(50):\n",
        "    train_iter.init_epoch()\n",
        "    n_correct, n_total = 0, 0\n",
        "    for batch_idx, batch in enumerate(train_iter):\n",
        "\n",
        "        # switch model to training mode, clear gradient accumulators\n",
        "        model.train(); optimizer.zero_grad()\n",
        "\n",
        "        iterations += 1\n",
        "\n",
        "        # forward pass\n",
        "        answer = model(batch)\n",
        "\n",
        "        # calculate accuracy of predictions in the current batch\n",
        "        n_correct += (torch.max(answer, 1)[1].view(batch.label.size()) == batch.label).sum().item()\n",
        "        n_total += batch.batch_size\n",
        "        train_acc = 100. * n_correct/n_total\n",
        "\n",
        "        # calculate loss of the network output with respect to training labels\n",
        "        loss = criterion(answer, batch.label)\n",
        "\n",
        "        # backpropagate and update optimizer learning rate\n",
        "        loss.backward(); optimizer.step()\n",
        "\n",
        "        if iterations % 1000 == 0:\n",
        "\n",
        "          # print progress message\n",
        "          print(log_template.format(time.time()-start, epoch, iterations, 1+batch_idx, len(train_iter), \n",
        "                                    100. * (1+batch_idx) / len(train_iter), loss.item(), ' '*8, n_correct/n_total*100, ' '*12))\n",
        "\n",
        "    # switch model to evaluation mode\n",
        "    model.eval(); dev_iter.init_epoch()\n",
        "\n",
        "    # calculate accuracy on validation set\n",
        "    n_dev_correct, dev_loss = 0, 0\n",
        "    with torch.no_grad():\n",
        "      for dev_batch_idx, dev_batch in enumerate(dev_iter):\n",
        "        answer = model(dev_batch)\n",
        "        n_dev_correct += (torch.max(answer, 1)[1].view(dev_batch.label.size()) == dev_batch.label).sum().item()\n",
        "        dev_loss = criterion(answer, dev_batch.label)\n",
        "    dev_acc = 100. * n_dev_correct / len(dev)\n",
        "\n",
        "    print(dev_log_template.format(time.time()-start,\n",
        "        epoch, iterations, 1+batch_idx, len(train_iter),\n",
        "        100. * (1+batch_idx) / len(train_iter), loss.item(), dev_loss.item(), train_acc, dev_acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b5-tAtQY1sLu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "  def __init__(self,config):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.config = config\n",
        "    #self.rnn = nn.RNN(input_size=config['d_embed'], hidden_size=config['d_hidden'],num_layers=config['n_layers'])\n",
        "    self.rnn = nn.GRU(input_size=config['d_embed'], hidden_size=config['d_hidden'],num_layers=config['n_layers'])\n",
        "    #self.rnn = nn.LSTM(input_size=config['d_embed'], hidden_size=config['d_hidden'],num_layers=config['n_layers'])\n",
        "  \n",
        "  def forward(self,inputs):\n",
        "    #bsz = inputs.size()[1]\n",
        "    #h0 = c0 = inputs.new_zeros(config['n_layers'], bsz, config['d_hidden'])\n",
        "    outputs, hidden = self.rnn(inputs)\n",
        "    #outputs, (hidden,cell) = self.rnn(inputs)\n",
        "    return outputs if config['attn'] else outputs[-1]\n",
        "  \n",
        "class MultiNLIClassifier(nn.Module):\n",
        "  def __init__(self,config):\n",
        "    super(MultiNLIClassifier, self).__init__()\n",
        "    self.config = config\n",
        "    self.embed = nn.Embedding(config['n_embed'], config['d_embed'])\n",
        "    self.encoder = Encoder(config)\n",
        "    self.encoder_p = Encoder(config)\n",
        "    self.encoder_h = Encoder(config)\n",
        "    \n",
        "#     self.relu = nn.ReLU()\n",
        "#     self.tanh = nn.Tanh()\n",
        "#     self.proj_p = nn.Linear(config['d_hidden'], config['d_hidden'])\n",
        "#     self.proj_h = nn.Linear(config['d_hidden'], config['d_hidden'])\n",
        "#     self.W = nn.Parameter(torch.randn(config['d_hidden'], 1))\n",
        "#     self.register_parameter('W', self.W)\n",
        "#     self.Wp = nn.Linear(config['d_hidden'], config['d_hidden'])\n",
        "#     self.Wh = nn.Linear(config['d_hidden'], config['d_hidden'])\n",
        "\n",
        "    self.out = nn.Linear(2*config['d_hidden'], config['d_out'])\n",
        "  \n",
        "  def forward(self,batch):\n",
        "#     print(batch.premise)\n",
        "    pre_emb = self.embed(batch.premise)\n",
        "    hyp_emb = self.embed(batch.hypothesis)\n",
        "    if self.config['freeze_emb']:\n",
        "      pre_emb =pre_emb.detach()\n",
        "      hyp_emb =hyp_emb.detach()\n",
        "    if self.config['attn']:\n",
        "      #Attention\n",
        "      prem = self.encoder_p(pre_emb).transpose(0,1)\n",
        "      hypo = self.encoder_h(hyp_emb)[-1].unsqueeze(2)\n",
        "#     M = self.tanh(self.proj_p(prem)+self.proj_h(hypo[None,:,:]))\n",
        "#     alpha = nn.functional.softmax(torch.bmm(M, self.W.unsqueeze(0).expand(prem.size(0), *self.W.size())).squeeze(-1))\n",
        "#     r = torch.bmm(prem.permute(1,2,0),alpha.transpose(0,1).unsqueeze(2)).squeeze(2)\n",
        "#     h = self.tanh(self.Wp(r)+self.Wh(hypo))\n",
        "#     logits = self.out(h)\n",
        "      M = torch.bmm(prem,hypo)\n",
        "      alpha = nn.functional.softmax(M,1)\n",
        "      r = torch.bmm(prem.transpose(1,2),alpha)\n",
        "      logits = self.out(torch.cat([r.squeeze(2),hypo.squeeze(2)],1))\n",
        "    else:\n",
        "      prem = self.encoder(pre_emb)\n",
        "      hypo = self.encoder(hyp_emb)\n",
        "      logits = self.out(torch.cat([prem,hypo],1))\n",
        "    \n",
        "    return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SuBSvbuugxBT",
        "colab_type": "code",
        "outputId": "674d2667-4125-46aa-a59f-10b3b49c430e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1902
        }
      },
      "cell_type": "code",
      "source": [
        "config = {}\n",
        "config['n_embed'] = len(inputs.vocab)\n",
        "config['d_embed'] = 100\n",
        "config['d_hidden'] = 300\n",
        "config['d_out'] = len(answers.vocab)\n",
        "config['n_layers'] = 1\n",
        "config['freeze_emb'] = 0\n",
        "config['attn'] = 0\n",
        "\n",
        "model = MultiNLIClassifier(config)\n",
        "print(model)\n",
        "model.embed.weight.data.copy_(inputs.vocab.vectors)\n",
        "model.to(device)\n",
        "train(model)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MultiNLIClassifier(\n",
            "  (embed): Embedding(93537, 100)\n",
            "  (encoder): Encoder(\n",
            "    (rnn): GRU(100, 300)\n",
            "  )\n",
            "  (encoder_p): Encoder(\n",
            "    (rnn): GRU(100, 300)\n",
            "  )\n",
            "  (encoder_h): Encoder(\n",
            "    (rnn): GRU(100, 300)\n",
            "  )\n",
            "  (out): Linear(in_features=600, out_features=4, bias=True)\n",
            ")\n",
            "  Time Epoch Iteration Progress    (%Epoch)   Loss   Dev/Loss     Accuracy  Dev/Accuracy\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 99%|█████████▉| 397721/400000 [00:30<00:00, 26229.12it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "    31     0      1000  1000/3068       33% 0.905556               47.2578             \n",
            "    60     0      2000  2000/3068       65% 0.878979               51.1418             \n",
            "    90     0      3000  3000/3068       98% 0.908266               52.7695             \n",
            "    93     0      3068  3068/3068      100% 0.944668 0.971513      52.8566      56.3627\n",
            "   122     1      4000   932/3068       30% 0.850833               60.1219             \n",
            "   152     1      5000  1932/3068       63% 0.879008               59.7980             \n",
            "   182     1      6000  2932/3068       96% 0.972808               59.7027             \n",
            "   187     1      6136  3068/3068      100% 0.870022 0.920061      59.6763      55.1401\n",
            "   214     2      7000   864/3068       28% 0.834036               64.9577             \n",
            "   244     2      8000  1864/3068       61% 0.810404               64.6053             \n",
            "   274     2      9000  2864/3068       93% 0.841195               64.2532             \n",
            "   281     2      9204  3068/3068      100% 0.833931 0.911737      64.1680      55.7412\n",
            "   306     3     10000   796/3068       26% 0.759665               69.9808             \n",
            "   336     3     11000  1796/3068       59% 0.657594               69.1019             \n",
            "   366     3     12000  2796/3068       91% 0.808477               68.5519             \n",
            "   375     3     12272  3068/3068      100% 0.725898 0.915030      68.4137      56.3118\n",
            "   398     4     13000   728/3068       24% 0.606839               74.3486             \n",
            "   427     4     14000  1728/3068       56% 0.686537               73.5121             \n",
            "   458     4     15000  2728/3068       89% 0.681420               72.7871             \n",
            "   469     4     15340  3068/3068      100% 0.791628 0.950640      72.5751      54.9975\n",
            "   490     5     16000   660/3068       22% 0.560814               78.9749             \n",
            "   520     5     17000  1660/3068       54% 0.527951               77.8756             \n",
            "   550     5     18000  2660/3068       87% 0.697878               77.0976             \n",
            "   563     5     18408  3068/3068      100% 0.568582 1.030231      76.8048      54.4575\n",
            "   582     6     19000   592/3068       19% 0.392104               82.6423             \n",
            "   612     6     20000  1592/3068       52% 0.433472               81.6230             \n",
            "   642     6     21000  2592/3068       84% 0.539267               80.8271             \n",
            "   657     6     21476  3068/3068      100% 0.600458 1.191508      80.5048      53.3877\n",
            "   675     7     22000   524/3068       17% 0.369612               85.9151             \n",
            "   705     7     23000  1524/3068       50% 0.325710               85.0537             \n",
            "   735     7     24000  2524/3068       82% 0.302497               84.2106             \n",
            "   751     7     24544  3068/3068      100% 0.514549 1.171177      83.8290      53.0820\n",
            "   766     8     25000   456/3068       15% 0.397348               88.6102             \n",
            "   796     8     26000  1456/3068       47% 0.239380               87.6331             \n",
            "   826     8     27000  2456/3068       80% 0.389756               86.9471             \n",
            "   845     8     27612  3068/3068      100% 0.341863 1.404505      86.5690      52.2262\n",
            "   858     9     28000   388/3068       13% 0.193770               90.8344             \n",
            "   888     9     29000  1388/3068       45% 0.240023               89.9501             \n",
            "   918     9     30000  2388/3068       78% 0.279611               89.1793             \n",
            "   939     9     30680  3068/3068      100% 0.290652 1.614282      88.7709      52.1345\n",
            "   950    10     31000   320/3068       10% 0.229315               92.3755             \n",
            "   979    10     32000  1320/3068       43% 0.237494               91.6175             \n",
            "  1009    10     33000  2320/3068       76% 0.179584               90.9476             \n",
            "  1033    10     33748  3068/3068      100% 0.260869 1.871632      90.5374      51.8594\n",
            "  1042    11     34000   252/3068        8% 0.137747               93.5330             \n",
            "  1071    11     35000  1252/3068       41% 0.193692               93.0012             \n",
            "  1102    11     36000  2252/3068       73% 0.246863               92.3471             \n",
            "  1127    11     36816  3068/3068      100% 0.243499 1.892262      91.8877      51.5436\n",
            "  1134    12     37000   184/3068        6% 0.173834               94.8072             \n",
            "  1163    12     38000  1184/3068       39% 0.156556               94.0199             \n",
            "  1193    12     39000  2184/3068       71% 0.233777               93.4402             \n",
            "  1221    12     39884  3068/3068      100% 0.217453 2.279718      92.9911      51.1156\n",
            "  1226    13     40000   116/3068        4% 0.093436               95.7907             \n",
            "  1256    13     41000  1116/3068       36% 0.135027               94.9499             \n",
            "  1285    13     42000  2116/3068       69% 0.182120               94.3614             \n",
            "  1315    13     42952  3068/3068      100% 0.202819 2.515229      93.8526      51.8186\n",
            "  1317    14     43000    48/3068        2% 0.096549               96.2565             \n",
            "  1348    14     44000  1048/3068       34% 0.132305               95.6181             \n",
            "  1378    14     45000  2048/3068       67% 0.248054               94.9688             \n",
            "  1407    14     46000  3048/3068       99% 0.106157               94.5361             \n",
            "  1409    14     46020  3068/3068      100% 0.197021 2.507416      94.5299      51.7066\n",
            "  1440    15     47000   980/3068       32% 0.129519               96.1511             \n",
            "  1470    15     48000  1980/3068       65% 0.140927               95.5106             \n",
            "  1500    15     49000  2980/3068       97% 0.142637               95.0443             \n",
            "  1503    15     49088  3068/3068      100% 0.226876 2.428597      94.9998      51.6149\n",
            "  1532    16     50000   912/3068       30% 0.106653               96.5298             \n",
            "  1562    16     51000  1912/3068       62% 0.070390               96.0059             \n",
            "  1592    16     52000  2912/3068       95% 0.111094               95.5161             \n",
            "  1597    16     52156  3068/3068      100% 0.164182 2.926601      95.4393      51.3602\n",
            "  1624    17     53000   844/3068       28% 0.130938               96.8398             \n",
            "  1654    17     54000  1844/3068       60% 0.108050               96.3446             \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-039ec1682202>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-8396ea5576cf>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# calculate accuracy of predictions in the current batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-86fce6e59f0e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     57\u001b[0m       \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhypo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m       \u001b[0mprem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre_emb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m       \u001b[0mhypo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyp_emb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m       \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprem\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhypo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-86fce6e59f0e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m#bsz = inputs.size()[1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m#h0 = c0 = inputs.new_zeros(config['n_layers'], bsz, config['d_hidden'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;31m#outputs, (hidden,cell) = self.rnn(inputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attn'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             result = _impl(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 179\u001b[0;31m                            self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             result = _impl(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "sZ-BNJxE7Ca8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}